{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6afee6",
   "metadata": {},
   "source": [
    "Toxicity detection model \n",
    "<span style=\"font-size: 15px;\">\n",
    "        \\\n",
    "        - a contextual languge model akin BERT/RoBERTa/XLnet\\\n",
    "        - detection for obvious slangs\\\n",
    "        - not associate repeated puncutation marks with negative scoring\\\n",
    "        - ability to provide as possible accurate scoring for sarcastic comments\\\n",
    "        - more..?\\\n",
    "</span>\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Training data:\n",
    "<span style=\"font-size: 15px;\">\n",
    "        \\\n",
    "        - Jigsaw unintended bias - https://www.kaggle.com/datasets/julian3833/jigsaw-toxic-comment-classification-challenge?select=train.csv \\\n",
    "        - Ruddit - https://github.com/hadarishav/Ruddit/tree/main/Dataset \\\n",
    "        - Real toxicity prompts - https://huggingface.co/datasets/allenai/real-toxicity-prompts\n",
    "</span>\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Testing data:\n",
    "<span style=\"font-size: 15px;\">\n",
    "        \\\n",
    "        - Chatlogs from LoL tribunal (system later phased out) - https://www.kaggle.com/datasets/simshengxue/league-of-legends-tribunal-chatlogs \\\n",
    "        - Friends tv show dialogues - https://www.kaggle.com/datasets/thedevastator/friends-tv-show-dialog-sequences \\\n",
    "        - Jigsaw unint. bias given test data - https://www.kaggle.com/datasets/julian3833/jigsaw-toxic-comment-classification-challenge?select=test.csv\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43be67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#core data handling\n",
    "import os\n",
    "import json\n",
    "from typing import List, Optional, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets import load_dataset #rtp streaming\n",
    "\n",
    "#models + evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, root_mean_squared_error, r2_score, \n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "import secrets\n",
    "RANDOM_SEED = secrets.randbelow(10000000)\n",
    "#print(\"Random seed:\", RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9f32f",
   "metadata": {},
   "source": [
    "Helpers for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "690f33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "# - if text/comment field is NaN (empty) -> \"\"\n",
    "# - \" hello world!  \" -> \"hello world\"\n",
    "# - o/w convert to string + remove spaces\n",
    "def cleanText(s: Any) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    if isinstance(s, str):   \n",
    "        return s.strip() \n",
    "    return str(s).strip() \n",
    "\n",
    "#linear scaling: \n",
    "# - clip value (if needed) to lie within the [prev_min, prev_max] range -> prevent outliers\n",
    "# - normalize/scale the value now in [0, 1]  \n",
    "# - stretch to [1, 5] from prev range!\n",
    "def toToxicRange(value: float, prev_min: float, prev_max: float) -> float:\n",
    "    if np.isnan(value):\n",
    "        return np.nan\n",
    "    clipped = float(np.clip(value, prev_min, prev_max))\n",
    "    scaled = (clipped - prev_min) / (prev_max - prev_min)\n",
    "    return 1 + 4 * scaled\n",
    "\n",
    "#Removes only:\n",
    "# - empty strings\n",
    "# - missing values\n",
    "# - '[deleted]', '[removed]'\n",
    "# - pure punctuation - texts with no letters/numbers (e.g. '!!!', '...', '?!!?')\n",
    "def isInformativeText(s: str) -> bool:\n",
    "    if not s:\n",
    "        return False\n",
    "    t = s.strip().lower()\n",
    "    if t in {\"\", \"[deleted]\", \"[removed]\"}:\n",
    "        return False\n",
    "    #remove strings entirely filled w/ punctuation\n",
    "    if isPunctuationOnly(t):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def isPunctuationOnly(s: str) -> bool:\n",
    "    t = s.strip()  #removes whitespace\n",
    "    if len(t) == 0:\n",
    "        return True\n",
    "    \n",
    "    #allowed punctuation chars\n",
    "    punct_chars = set(\"!?,.;:-—'\\\"()[]{}*/\\\\\")\n",
    "    return all(ch in punct_chars for ch in t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1604c6c",
   "metadata": {},
   "source": [
    "Jigsaw unintended bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ffc5ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load jigsaw data from csv and turn multiple binary toxicity columns into a 1–5 score\n",
    "# - reads only `max_rows` rows for speed (if given!)\n",
    "# - returns df with ['text', 'toxicity_score']\n",
    "def loadJigsaw(path: str, text_col: str = \"comment_text\", \n",
    "    tox_cols: Optional[List[str]] = None,\n",
    "    max_rows: Optional[int] = 6000) -> pd.DataFrame:\n",
    "    if tox_cols is None:\n",
    "        tox_cols = [\n",
    "            \"toxic\",\n",
    "            \"severe_toxic\",\n",
    "            \"obscene\",\n",
    "            \"threat\",\n",
    "            \"insult\",\n",
    "            \"identity_hate\",\n",
    "        ]\n",
    "\n",
    "    df = pd.read_csv(path, nrows=max_rows)\n",
    "    df[\"text\"] = df[text_col].apply(cleanText)\n",
    "\n",
    "    #flgs error when required column non-existent in dataset (unlikely)\n",
    "    existing = [c for c in tox_cols if c in df.columns]\n",
    "    if not existing:\n",
    "        raise ValueError(\n",
    "            f\"This column is not present! Here's what we DO have -> {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    for c in existing:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    sum_max = len(existing)  #max possible sum if all are 1\n",
    "    df[\"raw_toxic_sum\"] = df[existing].sum(axis=1)\n",
    "\n",
    "    #maps range [0..sum_max] -> [1..5]\n",
    "    df[\"toxicity_score\"] = df[\"raw_toxic_sum\"].apply(\n",
    "        lambda v: toToxicRange(v, 0.0, float(sum_max))\n",
    "    )\n",
    "\n",
    "    return df[[\"text\", \"toxicity_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b67c0",
   "metadata": {},
   "source": [
    "Reddit Annotated (Ruddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51924f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads ruddit csv with each row score in [-1, 1] -> converted \n",
    "# to a [1–5] toxicity scale\n",
    "def loadRuddit(path: str, text_col: str = \"body\",\n",
    "    score_col: str = \"score\",\n",
    "    #we're using the whole (short) dataset\n",
    "    max_rows: Optional[int] = None) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, nrows=max_rows)\n",
    "    df[\"text\"] = df[text_col].apply(cleanText)\n",
    "    df[score_col] = pd.to_numeric(df[score_col], errors=\"coerce\")\n",
    "\n",
    "    #entries with missing score removed!\n",
    "    df = df.dropna(subset=[score_col])\n",
    "\n",
    "    df[\"toxicity_score\"] = df[score_col].apply(\n",
    "        lambda v: toToxicRange(v, -1.0, 1.0)  #from [-1, 1] -> [1, 5]\n",
    "    )\n",
    "\n",
    "    return df[[\"text\", \"toxicity_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de2089",
   "metadata": {},
   "source": [
    "Real Toxcicity Prompts (allenai) - processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dc2da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming sample of RTP data from huggingface \n",
    "# - convert to [1–5] scale\n",
    "# - uses 'continuation.toxicity' if available, else 'prompt.toxicity\n",
    "# - toxicity scores are originally in [0,1]\n",
    "def loadRTP(n_samples=6000, prefer_continuation=True):\n",
    "    stream = load_dataset(\n",
    "        \"allenai/real-toxicity-prompts\",\n",
    "        split=\"train\",\n",
    "        streaming=True\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for i, rec in enumerate(stream):\n",
    "        if i >= n_samples:\n",
    "            break\n",
    "        \n",
    "        p = rec.get(\"prompt\", {})\n",
    "        c = rec.get(\"continuation\", {})\n",
    "\n",
    "        prompt_text = cleanText(p.get(\"text\", \"\")) if isinstance(p, dict) else \"\"\n",
    "        cont_text = cleanText(c.get(\"text\", \"\")) if isinstance(c, dict) else \"\"\n",
    "\n",
    "        if prefer_continuation and cont_text:\n",
    "            text = cont_text\n",
    "            tox = c.get(\"toxicity\", p.get(\"toxicity\", None))\n",
    "        else:\n",
    "            text = (prompt_text + \" \" + cont_text).strip()\n",
    "            tox = c.get(\"toxicity\", p.get(\"toxicity\", None))\n",
    "\n",
    "        rows.append({\"text\": text, \"raw_toxicity\": tox})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"raw_toxicity\"] = pd.to_numeric(df[\"raw_toxicity\"], errors=\"coerce\")\n",
    "    df[\"toxicity_score\"] = df[\"raw_toxicity\"].apply(\n",
    "        lambda v: toToxicRange(v, 0.0, 1.0)\n",
    "    )\n",
    "\n",
    "    return df[[\"text\", \"toxicity_score\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150cbfe",
   "metadata": {},
   "source": [
    "Retraining model using ingame chat log data - GameTox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7308650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGameTox(path: str, text_col: str = \"message\", label_col: str = \"label\", \n",
    "    max_rows: Optional[int] = 6000) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, nrows=max_rows)\n",
    "    df[\"text\"] = df[text_col].apply(cleanText)\n",
    "    \n",
    "    #convert multi-class intent (0..5) → [1..5] toxicity range\n",
    "    df[\"toxicity_score\"] = df[label_col].apply(lambda v: toToxicRange(v, 0.0, 5.0))\n",
    "\n",
    "    #keeps only required columns\n",
    "    return df[[\"text\", \"toxicity_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344ac0d",
   "metadata": {},
   "source": [
    "clean and merge helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bb9b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applies a 2nd round of cleaning:\n",
    "# - enforces text type,\n",
    "# - removes empty / '[deleted]' / very short - if any\n",
    "# - drop duplicates\n",
    "def cleanAndMergeTrainingData(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"text\"] = df[\"text\"].apply(cleanText)\n",
    "    df = df[df[\"text\"].apply(isInformativeText)]\n",
    "\n",
    "    df = df.dropna(subset=[\"toxicity_score\"])\n",
    "    df = df[df[\"toxicity_score\"].apply(lambda x: not pd.isna(x))]\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"text\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#merge multiple [text, toxicity_score] dfs into one\n",
    "def mergeDatasets(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    cleaned = []\n",
    "    for d in dfs:\n",
    "        d = d.copy()\n",
    "        if not {\"text\", \"toxicity_score\"}.issubset(d.columns):\n",
    "            raise ValueError(\"Dataset missing required columns.\")\n",
    "        cleaned.append(d[[\"text\", \"toxicity_score\"]])\n",
    "\n",
    "    combined = pd.concat(cleaned, ignore_index=True)\n",
    "    combined = cleanAndMergeTrainingData(combined)\n",
    "    combined = combined.sample(frac=1.0, random_state=42)\n",
    "\n",
    "    return combined.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62f42dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 2)\n",
      "(5966, 2)\n",
      "(6000, 2)\n",
      "(6000, 2)\n"
     ]
    }
   ],
   "source": [
    "jigsawDF = loadJigsaw(\"jigsaw_train.csv\")\n",
    "rudditDF = loadRuddit(\"ruddit_train.csv\")\n",
    "rtpDF = loadRTP(6000)\n",
    "gametoxDF = loadGameTox(\"gametox_train.csv\")\n",
    "\n",
    "#individual dataframes\n",
    "print(jigsawDF.shape) #prints -> (# of entries, # of columns) \n",
    "print(rudditDF.shape)\n",
    "print(rtpDF.shape)\n",
    "print(gametoxDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b844ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe looks like this ->  (22028, 2)\n",
      "                                                text  toxicity_score\n",
      "0               play some good footy here long-term.        1.254586\n",
      "1  with Packers and Cardinals coming in at 10/1 (...        1.409145\n",
      "2  It's the Palace of Westminster not Buckingham ...        2.292000\n",
      "3                    ya spotting the hil im guessing        1.000000\n",
      "4  and I had on Twitter shortly after LeVar and I...        1.165766\n"
     ]
    }
   ],
   "source": [
    "#combined dataframe\n",
    "combinedDF = mergeDatasets([jigsawDF, rudditDF, rtpDF, gametoxDF])\n",
    "print(\"Combined dataframe looks like this -> \", combinedDF.shape)\n",
    "print(combinedDF.head())\n",
    "combinedDF.to_csv(\"combined_toxicity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede821a",
   "metadata": {},
   "source": [
    "Train/Validation/Test  -- splitting - widely recommended 80/10/10 in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cce34567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17622 2203 2203\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    #80(train)-20(in temp -> later split for validation + test) split\n",
    "    combinedDF[\"text\"], combinedDF[\"toxicity_score\"], test_size=0.2, random_state=123\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=123)\n",
    "print(len(X_train), len(X_val), len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035cc341",
   "metadata": {},
   "source": [
    "Regression metrics - Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92595f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": root_mean_squared_error(y_true, y_pred),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "def to_binary_labels(y, threshold=3.0):\n",
    "    return (np.array(y) >= threshold).astype(int)\n",
    "\n",
    "def classification_metrics(y_true_scores, y_pred_scores, threshold=3.0):\n",
    "    y_true = to_binary_labels(y_true_scores, threshold)\n",
    "    y_pred = to_binary_labels(y_pred_scores, threshold)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred_scores)\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"ROC_AUC\": auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1388c",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge\n",
    "# - strong Linear Baseline\n",
    "# - standard linear model often used in text regression/classification tasks with TF-IDF\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=40_000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    ")\n",
    "\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_val_vec = tfidf.transform(X_val)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_vec, y_train)\n",
    "\n",
    "ridge_pred = ridge.predict(X_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = regression_metrics(y_test, ridge_pred)\n",
    "ridge_cls = classification_metrics(y_test, ridge_pred)\n",
    "\n",
    "print(\"Ridge Regression -> \", ridge_reg)\n",
    "print(\"Ridge Classification -> \", ridge_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a7d11",
   "metadata": {},
   "source": [
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "# - non-linear classical ml baseline\n",
    "# - intended to capture non-linear interactions between TF–IDF features\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_vec, y_train)\n",
    "rf_pred = rf.predict(X_test_vec)\n",
    "\n",
    "rf_reg = regression_metrics(y_test, rf_pred)\n",
    "rf_cls = classification_metrics(y_test, rf_pred)\n",
    "\n",
    "print(\"RF Regression -> \", rf_reg)\n",
    "print(\"RF Classification -> \", rf_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a70d0",
   "metadata": {},
   "source": [
    "Model3 -> ⭐ Chosen One ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b92dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#DistilRoBERTa\n",
    "# - deep neural contextual language model\n",
    "# - input representation: token embeddings + attention\n",
    "# - captures context, sarcasm, slang, punctuation nuance\n",
    "# - learns toxic patterns beyond simple word frequency\n",
    "# - represents the modern SOTA transformer approach\n",
    "# - faster+lightweight compared to BERT/RoBERTa\n",
    "\n",
    "model_name = \"distilroberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=1, #regression head\n",
    "    problem_type=\"regression\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04dbdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=64,       # -- changed 128 -> 64 (baseline) - some text cutoff due to lowering this\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "train_ds = ToxicityDataset(X_train, y_train)\n",
    "val_ds   = ToxicityDataset(X_val, y_val)\n",
    "test_ds  = ToxicityDataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11d1a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf6d98",
   "metadata": {},
   "source": [
    "Predict w/distilroberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a83425c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilroberta_toxicity\",\n",
    "    learning_rate=3e-5,                 #slightly higher for small batch size\n",
    "    per_device_train_batch_size=16,      #smaller batch (faster, safer)\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,                 #1 epoch -> enough (and fast)\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,                          #use if GPU supports it -> edit:safe to keep!!\n",
    "    logging_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d9e948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2477e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1102' max='1102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1102/1102 59:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.877800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.320600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.297100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.218900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.202900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.221900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.204100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.250100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1102, training_loss=0.30011083188377147, metrics={'train_runtime': 3571.8422, 'train_samples_per_second': 4.934, 'train_steps_per_second': 0.309, 'total_flos': 291787358683392.0, 'train_loss': 0.30011083188377147, 'epoch': 1.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72af500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa Regression: {'MAE': 0.27435488114883483, 'RMSE': 0.4308894795310864, 'R2': 0.7865369541069497}\n",
      "RoBERTa Classification: {'Precision': 0.7580071174377224, 'Recall': 0.75, 'F1': 0.7539823008849558, 'ROC_AUC': 0.9627795433360979}\n"
     ]
    }
   ],
   "source": [
    "pred_output = trainer.predict(test_ds)\n",
    "distilroberta_pred = pred_output.predictions.flatten()\n",
    "\n",
    "distilroberta_reg = regression_metrics(y_test, distilroberta_pred)\n",
    "distilroberta_cls = classification_metrics(y_test, distilroberta_pred)\n",
    "\n",
    "print(\"RoBERTa Regression:\", distilroberta_reg)\n",
    "print(\"RoBERTa Classification:\", distilroberta_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66f4b840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('final_toxicity_model_adapted\\\\tokenizer_config.json',\n",
       " 'final_toxicity_model_adapted\\\\special_tokens_map.json',\n",
       " 'final_toxicity_model_adapted\\\\vocab.json',\n",
       " 'final_toxicity_model_adapted\\\\merges.txt',\n",
       " 'final_toxicity_model_adapted\\\\added_tokens.json',\n",
       " 'final_toxicity_model_adapted\\\\tokenizer.json')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store the final trained model\n",
    "save_dir = \"final_toxicity_model_adapted\"\n",
    "trainer.save_model(save_dir)\n",
    "\n",
    "#saves tokenizer files such as vocab, merges, tokenizer.json, etc\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68536a0",
   "metadata": {},
   "source": [
    "Test suite will consist of: - test code cleared, test results stored!\\\n",
    "<span style=\"font-size: 15px;\">\n",
    "    \\\n",
    "    (more related to our project)\\\n",
    "    - jigsaw test data - same domain as training data\\\n",
    "    - game chats - LoL - tribunal chat logs\\\n",
    "</span>\n",
    "<span style=\"font-size: 15px;\">\n",
    "    (fun, side testing)\\\n",
    "    - daily conversation, funny/sarcastic comments - TV shows\\\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model from HuggingFace repo\n",
    "#model_name = \"visha007/ToxiMuncher-Lite\" #baseline model\n",
    "model_name = \"visha007/ToxiMuncher-Pro\" #baseline model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "#model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
